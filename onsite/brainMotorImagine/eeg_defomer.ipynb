{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyoZH6XY7F_4"
      },
      "source": [
        "#P'Ro data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHMLPj3Z7LPG"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/ss4-exp-datasource/brainWaveDataset/chunk_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gcqm-mfh7TE4"
      },
      "outputs": [],
      "source": [
        "!unzip chunk_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1WvsEsEDWS-"
      },
      "source": [
        "## ohm code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYj0261lk0Ie"
      },
      "outputs": [],
      "source": [
        "chunk = pd.read_csv(\"/content/chunk_data/chunk_data.csv\")\n",
        "chunk[\"X_numpy\"] = chunk[\"X\"].apply(lambda x : np.load(\"/content/chunk_data/\"+x))\n",
        "chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQodQ2QBlQs_"
      },
      "outputs": [],
      "source": [
        "dict_val = {\n",
        "    110:0,\n",
        "    120:1,\n",
        "    150:2\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Xj8zsDlVam"
      },
      "outputs": [],
      "source": [
        "chunk[\"y\"] = chunk[\"y\"].apply(lambda x : dict_val[x])\n",
        "chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9ajAQo2laN-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = chunk[\"X_numpy\"]\n",
        "y = chunk[\"y\"]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8,random_state=888)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT74OCGClv-e"
      },
      "outputs": [],
      "source": [
        "max_shape = tuple(max(sizes) for sizes in zip(*(arr.shape for arr in X_train)))\n",
        "def pad_to_shape(arr, target_shape):\n",
        "    result = np.zeros(target_shape)\n",
        "    result[:arr.shape[0], :arr.shape[1]] = arr\n",
        "\n",
        "    return result\n",
        "# Pad all arrays to the target shape\n",
        "padded_x_train = X_train.apply(lambda x: pad_to_shape(x, max_shape))\n",
        "padded_x_val = X_val.apply(lambda x: pad_to_shape(x, max_shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW8w_2iEmQrF"
      },
      "outputs": [],
      "source": [
        "stacked_X_train = np.stack(padded_x_train .values)\n",
        "stacked_X_train_T = np.transpose(stacked_X_train, (0, 2, 1))\n",
        "\n",
        "stacked_X_val = np.stack(padded_x_val.values)\n",
        "stacked_X_val_T = np.transpose(stacked_X_val, (0, 2, 1))\n",
        "stacked_y_train = np.array(y_train)\n",
        "stacked_y_val = np.array(y_val)\n",
        "stacked_X_train_T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRGmG0EUl1Rv"
      },
      "outputs": [],
      "source": [
        "padded_x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UHUf6zTFb1H"
      },
      "source": [
        "## my code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvmBel627e9x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "chunk_data = pd.read_csv(\"chunk_data/chunk_data.csv\")\n",
        "chunk_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW_2akMMMhlA"
      },
      "outputs": [],
      "source": [
        "npy_data = np.load('chunk_data/' + chunk_data['X'][2])\n",
        "npy_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAVwDSaONFbA"
      },
      "outputs": [],
      "source": [
        "npy_data = npy_data.reshape(8,1741)\n",
        "npy_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_StLM9HxNkRw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "t_data = np.expand_dims(npy_data, axis=0)\n",
        "t_data = torch.tensor(t_data)\n",
        "t_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_GPR_6PPOzo"
      },
      "outputs": [],
      "source": [
        "t_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06awwyJPkTaO"
      },
      "outputs": [],
      "source": [
        "# max_shape = tuple(max(sizes) for sizes in zip(*(arr.shape for arr in X_train)))\n",
        "# def pad_to_shape(arr, target_shape):\n",
        "#     result = np.zeros(target_shape)\n",
        "#     result[:arr.shape[0], :arr.shape[1]] = arr\n",
        "\n",
        "#     return result\n",
        "# # Pad all arrays to the target shape\n",
        "# padded_x_train = X_train.apply(lambda x: pad_to_shape(x, max_shape))\n",
        "# padded_x_val = X_val.apply(lambda x: pad_to_shape(x, max_shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msmFSNZoh9mI"
      },
      "outputs": [],
      "source": [
        "npy_data_2 = np.load('chunk_data/' + chunk_data['X'][100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uqmf215iBv3"
      },
      "outputs": [],
      "source": [
        "npy_data_2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Ly0EhJMYRK"
      },
      "source": [
        "## fourier transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzWQxVHs8Ir3"
      },
      "outputs": [],
      "source": [
        "npy_data = np.load('chunk_data/' + chunk_data['X'][0])\n",
        "df = pd.DataFrame(npy_data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD90EZybdh2n"
      },
      "outputs": [],
      "source": [
        "channel = npy_data[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhEmNhbr-eXY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(channel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lafs2yrE__mJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fft import fft, ifft, fftfreq\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs):\n",
        "    # Compute the Fourier transform of the signal\n",
        "    fft_data = fft(data)\n",
        "\n",
        "    # Define the frequencies\n",
        "    freqs = fftfreq(len(data), 1/fs)\n",
        "\n",
        "    # Create a filter in the frequency domain\n",
        "    filter = np.ones(len(data))\n",
        "    filter[(freqs < lowcut) | (freqs > highcut)] = 0\n",
        "\n",
        "    # Apply the filter in the frequency domain\n",
        "    filtered_fft_data = fft_data * filter\n",
        "\n",
        "    return filtered_fft_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME6U9YSh_1vx"
      },
      "outputs": [],
      "source": [
        "# Assuming test_data is your NumPy array\n",
        "data_sampling_rate = 250\n",
        "# Define the number of channels\n",
        "num_channels = npy_data.shape[1]\n",
        "\n",
        "# Loop through each channel\n",
        "for i in range(8):\n",
        "  # Extract data for current channel\n",
        "  channel_data = npy_data[:, i]\n",
        "\n",
        "  # Compute the Fourier transform (FFT)\n",
        "  fft_data = fft(channel_data)\n",
        "\n",
        "  # Calculate corresponding frequencies\n",
        "  freqs = fftfreq(len(channel_data)) * (data_sampling_rate / 2)  # Assuming you know the sampling rate\n",
        "\n",
        "  # Plot absolute value of FFT (magnitude spectrum)\n",
        "  plt.plot(freqs, abs(fft_data))\n",
        "  plt.xlabel(\"Frequency (Hz)\")\n",
        "  plt.ylabel(\"Magnitude\")\n",
        "  plt.title(f\"Channel_{i+1} - Fourier Transform\")\n",
        "  # plt.xlim(0, data_sampling_rate / 2)  # Adjust x-axis limit based on sampling rate\n",
        "  plt.xlim(0, max(freqs))  # Adjust x-axis limit based on sampling rate\n",
        "  plt.yscale(\"log\")  # Logarithmic scale for better visualization of magnitude spectrum\n",
        "\n",
        "  # Show the plot for current channel (optional)\n",
        "  plt.show()\n",
        "  break\n",
        "\n",
        "# You can show all plots at once after the loop\n",
        "plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl4k6Z5REP3i"
      },
      "outputs": [],
      "source": [
        "# Assuming test_data is your NumPy array\n",
        "data_sampling_rate = 250\n",
        "# Define the number of channels\n",
        "num_channels = npy_data.shape[1]\n",
        "\n",
        "# Loop through each channel\n",
        "for i in range(8):\n",
        "  # Extract data for current channel\n",
        "  channel_data = npy_data[:, i]\n",
        "\n",
        "  # Compute the Fourier transform of the signal\n",
        "  fft_data = fft(channel_data)\n",
        "\n",
        "  # Define the frequencies\n",
        "  freqs = fftfreq(len(channel_data)) * (data_sampling_rate / 2)  # Assuming you know the sampling rate\n",
        "\n",
        "    # Create a filter in the frequency domain\n",
        "  filter = np.ones(len(channel_data))\n",
        "  filter[(freqs < 13) | (freqs > 30)] = 0\n",
        "\n",
        "  # Apply the filter in the frequency domain\n",
        "  filtered_fft_data = fft_data * filter\n",
        "\n",
        "  # Calculate corresponding frequencies\n",
        "\n",
        "\n",
        "  # Plot absolute value of FFT (magnitude spectrum)\n",
        "  plt.plot(freqs, abs(filtered_fft_data))\n",
        "  plt.xlabel(\"Frequency (Hz)\")\n",
        "  plt.ylabel(\"Magnitude\")\n",
        "  plt.title(f\"Channel_{i+1} - Fourier Transform\")\n",
        "  # plt.xlim(0, data_sampling_rate / 2)  # Adjust x-axis limit based on sampling rate\n",
        "  plt.xlim(0, max(freqs))  # Adjust x-axis limit based on sampling rate\n",
        "  plt.yscale(\"log\")  # Logarithmic scale for better visualization of magnitude spectrum\n",
        "\n",
        "  # Show the plot for current channel (optional)\n",
        "  plt.show()\n",
        "  break\n",
        "\n",
        "# You can show all plots at once after the loop\n",
        "plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG_ic4Sayn-n"
      },
      "source": [
        "# P' Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQHsSH9vyrF3"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUXAgzfIzEEO"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login() # 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtwKTK8tyv1e"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Expss4/chunk_train_seq\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAUxFLFJzbxx"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train']\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_train = pd.DataFrame(train_dataset)\n",
        "df_train"
      ],
      "metadata": {
        "id": "VPDnbUF4GZys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "hs6-KKdUG7ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.chunk_seq[0]"
      ],
      "metadata": {
        "id": "LsHJg9SDj-fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.array(df_train.chunk_seq[0]).shape"
      ],
      "metadata": {
        "id": "BveVKKD8G_GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Train data"
      ],
      "metadata": {
        "id": "KyV8CIt8agOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "g6qkuRQAb2UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login() # 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"
      ],
      "metadata": {
        "id": "fnLbKSUzmcbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Expss4/train_seq_updated\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "p8Kim-L2b2Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset['train']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "SG7HO6x9b2Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_train = pd.DataFrame(train_dataset)\n",
        "df_train"
      ],
      "metadata": {
        "id": "Vn73R3Ynb12u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(df_train.label).value_counts()"
      ],
      "metadata": {
        "id": "zUTiWtDEJhma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "On8ELt4cm4-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.array(df_train.arr[0]).shape"
      ],
      "metadata": {
        "id": "pLFYRdd-nB71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-vKapMLdm7J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSbOL_QtAr8u"
      },
      "source": [
        "# EEG-Defomer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2er7BJHrBDsm"
      },
      "outputs": [],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7FJwCDmA9fG"
      },
      "outputs": [],
      "source": [
        "# This is the script of EEG-Deformer\n",
        "# This is the network script\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "\n",
        "def pair(t):\n",
        "    return t if isinstance(t, tuple) else (t, t)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def cnn_block(self, in_chan, kernel_size, dp):\n",
        "        return nn.Sequential(\n",
        "            nn.Dropout(p=dp),\n",
        "            nn.Conv1d(in_channels=in_chan, out_channels=in_chan,\n",
        "                      kernel_size=kernel_size, padding=self.get_padding_1D(kernel=kernel_size)),\n",
        "            nn.BatchNorm1d(in_chan),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, in_chan, fine_grained_kernel=11, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for i in range(depth):\n",
        "            dim = int(dim * 0.5)\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout),\n",
        "                FeedForward(dim, mlp_dim, dropout=dropout),\n",
        "                self.cnn_block(in_chan=in_chan, kernel_size=fine_grained_kernel, dp=dropout)\n",
        "            ]))\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        dense_feature = []\n",
        "        for attn, ff, cnn in self.layers:\n",
        "            x_cg = self.pool(x)\n",
        "            x_cg = attn(x_cg) + x_cg\n",
        "            x_fg = cnn(x)\n",
        "            x_info = self.get_info(x_fg)  # (b, in_chan)\n",
        "            dense_feature.append(x_info)\n",
        "            x = ff(x_cg) + x_fg\n",
        "        x_dense = torch.cat(dense_feature, dim=-1)  # b, in_chan*depth\n",
        "        x = x.view(x.size(0), -1)   # b, in_chan*d_hidden_last_layer\n",
        "        emd = torch.cat((x, x_dense), dim=-1)  # b, in_chan*(depth + d_hidden_last_layer)\n",
        "        return emd\n",
        "\n",
        "    def get_info(self, x):\n",
        "        # x: b, k, l\n",
        "        x = torch.log(torch.mean(x.pow(2), dim=-1))\n",
        "        return x\n",
        "\n",
        "    def get_padding_1D(self, kernel):\n",
        "        return int(0.5 * (kernel - 1))\n",
        "\n",
        "\n",
        "class Conv2dWithConstraint(nn.Conv2d):\n",
        "    def __init__(self, *args, doWeightNorm=True, max_norm=1, **kwargs):\n",
        "        self.max_norm = max_norm\n",
        "        self.doWeightNorm = doWeightNorm\n",
        "        super(Conv2dWithConstraint, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.doWeightNorm:\n",
        "            self.weight.data = torch.renorm(\n",
        "                self.weight.data, p=2, dim=0, maxnorm=self.max_norm\n",
        "            )\n",
        "        return super(Conv2dWithConstraint, self).forward(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- OG from github repo"
      ],
      "metadata": {
        "id": "ygrEZ0R4S8Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Deformer(nn.Module):\n",
        "    def cnn_block(self, out_chan, kernel_size, num_chan):\n",
        "        return nn.Sequential(\n",
        "            Conv2dWithConstraint(1, out_chan, kernel_size, padding=self.get_padding(kernel_size[-1]), max_norm=2),\n",
        "            Conv2dWithConstraint(out_chan, out_chan, (num_chan, 1), padding=0, max_norm=2),\n",
        "            nn.BatchNorm2d(out_chan),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d((1, 2), stride=(1, 2))\n",
        "        )\n",
        "\n",
        "    def __init__(self, *, num_chan, num_time, temporal_kernel, num_kernel=64,\n",
        "                 num_classes, depth=4, heads=16,\n",
        "                 mlp_dim=16, dim_head=16, dropout=0.):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn_encoder = self.cnn_block(out_chan=num_kernel, kernel_size=(1, temporal_kernel), num_chan=num_chan)\n",
        "\n",
        "        dim = int(0.5 * num_time)  # embedding size after the first cnn encoder\n",
        "\n",
        "        self.to_patch_embedding = Rearrange('b k c f -> b k (c f)')\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_kernel, dim))\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            dim=dim, depth=depth, heads=heads, dim_head=dim_head,\n",
        "            mlp_dim=mlp_dim, dropout=dropout,\n",
        "            in_chan=num_kernel, fine_grained_kernel=temporal_kernel,\n",
        "        )\n",
        "\n",
        "        L = self.get_hidden_size(input_size=dim, num_layer=depth)\n",
        "\n",
        "        out_size = int(num_kernel * L[-1]) + int(num_kernel * depth)\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.Linear(out_size, num_classes),\n",
        "            nn.Softmax(dim=1)  # Add Softmax layer here\n",
        "        )\n",
        "\n",
        "    def forward(self, eeg):\n",
        "        # eeg: (b, chan, time)\n",
        "        eeg = torch.unsqueeze(eeg, dim=1)  # (b, 1, chan, time)\n",
        "        x = self.cnn_encoder(eeg)  # (b, num_kernel, 1, 0.5*num_time)\n",
        "\n",
        "        x = self.to_patch_embedding(x)\n",
        "\n",
        "        b, n, _ = x.shape\n",
        "        x += self.pos_embedding\n",
        "        x = self.transformer(x)\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "    def get_padding(self, kernel):\n",
        "        return (0, int(0.5 * (kernel - 1)))\n",
        "\n",
        "    def get_hidden_size(self, input_size, num_layer):\n",
        "        return [int(input_size * (0.5 ** i)) for i in range(num_layer + 1)]"
      ],
      "metadata": {
        "id": "IU0lg5OAS7Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = torch.ones((16, 32, 1000))\n",
        "    emt = Deformer(num_chan=32, num_time=1000, temporal_kernel=11, num_kernel=64,\n",
        "                   num_classes=2, depth=4, heads=16,\n",
        "                   mlp_dim=16, dim_head=16, dropout=0.5)\n",
        "    # print(emt)\n",
        "    print(count_parameters(emt))\n",
        "\n",
        "    out = emt(data)\n",
        "    print(out)"
      ],
      "metadata": {
        "id": "gzRrG1xYH4I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## try to infer"
      ],
      "metadata": {
        "id": "GRJs3H9vIESl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkRjF8NMAw-O"
      },
      "outputs": [],
      "source": [
        "mynet = Deformer(\n",
        "    num_chan=8,\n",
        "    num_time=865,\n",
        "    temporal_kernel=13,  # using odd number to ensure \"same\" padding\n",
        "    num_kernel=64,\n",
        "    num_classes=3,\n",
        "    depth=4,\n",
        "    heads=16,\n",
        "    mlp_dim=16,\n",
        "    dim_head=16,\n",
        "    dropout=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaPAAaO6BTsO"
      },
      "outputs": [],
      "source": [
        "data = torch.randn(3, 8, 865)  # (batch_size=1, EEG_channel=30, data_points=384)  # change this according to your dataset\n",
        "data, data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX_FWEu5BrsA"
      },
      "outputs": [],
      "source": [
        "preds = mynet(data)\n",
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqZa2L5DH9Tg"
      },
      "outputs": [],
      "source": [
        "t_data, t_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlNgQGd-gk4Y"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "Q9HZYyqZhLZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## debug data"
      ],
      "metadata": {
        "id": "6ThHvZH8r6NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
        "  print(f\"Fold {fold+1} of 4\")\n",
        "  print(train_idx, val_idx)"
      ],
      "metadata": {
        "id": "DsLFlSzfKHtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torch.utils.data.Subset(train_dataset, train_idx)\n",
        "val_set = torch.utils.data.Subset(train_dataset, val_idx)\n",
        "train_set.indices, val_set.indices"
      ],
      "metadata": {
        "id": "vYMPk_-XR5Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.indices.shape, val_set.indices.shape"
      ],
      "metadata": {
        "id": "3IxZs9QVbwgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_set, batch_size=eval_batch_size, shuffle=False)\n",
        "train_dataloader, val_dataloader"
      ],
      "metadata": {
        "id": "0JtsgyRdSI8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(val_dataloader)"
      ],
      "metadata": {
        "id": "FzzLvr__XZSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, batch in enumerate(tqdm(val_dataloader)):\n",
        "    inputs, targets = batch\n",
        "    print(inputs, targets)\n",
        "    break"
      ],
      "metadata": {
        "id": "zSLnjwc1T7ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defg = batch[targets]\n",
        "defg"
      ],
      "metadata": {
        "id": "3Fan2vXIjYss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defg.shape"
      ],
      "metadata": {
        "id": "IiwmhLhQmZBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_lab = {110:0, 120:1, 150:2}\n",
        "lab_to_int = {0:110, 1:120, 2:150}"
      ],
      "metadata": {
        "id": "r2YY18uYyAmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defg[1] = int_to_lab[defg[1]]"
      ],
      "metadata": {
        "id": "lqh19hqU4bj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defg = defg.tolist()\n",
        "for i in range(len(defg)):\n",
        "  defg[i] = int_to_lab[defg[i]]\n",
        "\n",
        "defg"
      ],
      "metadata": {
        "id": "Zm0AJDs13OVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Tensor(defg)"
      ],
      "metadata": {
        "id": "dUpGRPbh5WGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Tensor(defg).dtype"
      ],
      "metadata": {
        "id": "Lmywl8bo5qEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = torch.stack([torch.stack(b_i) for b_i in batch[inputs]])\n",
        "abc.shape"
      ],
      "metadata": {
        "id": "MKrMpbxmizd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = torch.transpose(abc, 0, 2)\n",
        "abc, abc.shape"
      ],
      "metadata": {
        "id": "pEjP5J38opX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc[0].shape"
      ],
      "metadata": {
        "id": "64IZpz2moDYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc_t = torch.transpose(abc, 1, 2)\n",
        "abc_t, abc_t.shape"
      ],
      "metadata": {
        "id": "ZOy5wB87k6UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(batch[inputs]).shape"
      ],
      "metadata": {
        "id": "vrqI77fUfM5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = abc.to(torch.float32)\n",
        "abc.dtype"
      ],
      "metadata": {
        "id": "-rCyiRM87Oul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdCrio3HZd8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "gsV9PlzarzTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmJidV-mdT7D"
      },
      "outputs": [],
      "source": [
        "# Gradient Accumulation Settings\n",
        "# Set to 1 for no accumulation\n",
        "train_batch_size = 8\n",
        "eval_batch_size = 16\n",
        "num_accumulate = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckTyzfKsgcSG"
      },
      "outputs": [],
      "source": [
        "!pip install -q evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc7YinBzgPF8"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import torch.nn as nn\n",
        "\n",
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Cross Validation Configuration\n",
        "k_splits = 4\n",
        "metric = evaluate.load(\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e5wZaOkgtgn"
      },
      "outputs": [],
      "source": [
        "# Cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=k_splits, shuffle=True, random_state=42)\n",
        "kf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3i0h2wKgYOf"
      },
      "outputs": [],
      "source": [
        "# Select device\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lSebhM-FSWQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8h9321wdT23"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "all_eval_scores = []\n",
        "int_to_lab = {110:0, 120:1, 150:2}\n",
        "lab_to_int = {0:110, 1:120, 2:150}\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
        "    print(f\"Fold {fold+1} of 4\")\n",
        "\n",
        "    # Load Model\n",
        "    model = Deformer(\n",
        "        num_chan=8,\n",
        "        num_time=865,   # 1734 old train, 36 ohm, 865 janeta\n",
        "        temporal_kernel=13,  # using odd number to ensure \"same\" padding\n",
        "        num_kernel=64,\n",
        "        num_classes=3,\n",
        "        depth=4,\n",
        "        heads=16,\n",
        "        mlp_dim=16,\n",
        "        dim_head=16,\n",
        "        dropout=0.5\n",
        "    ).to(device)\n",
        "\n",
        "    # Optimizers specified in the torch.optim package\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Load Data: split train and valition set based on kfold\n",
        "    train_set = torch.utils.data.Subset(train_dataset, train_idx)\n",
        "    val_set = torch.utils.data.Subset(train_dataset, val_idx)\n",
        "\n",
        "    train_dataloader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_set, batch_size=eval_batch_size, shuffle=False)\n",
        "\n",
        "    # Reset Model Info\n",
        "    info = {\n",
        "        \"metric_train\": [],\n",
        "        \"metric_val\": [],\n",
        "        \"train_loss\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"best_metric_val\": -999,\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss_epoch = []\n",
        "        val_loss_epoch = []\n",
        "\n",
        "        train_preds = []\n",
        "        train_targets = []\n",
        "\n",
        "        val_preds = []\n",
        "        val_targets = []\n",
        "\n",
        "        num_updates = epoch * len(train_dataloader)\n",
        "\n",
        "        ### === Train Loop === ###\n",
        "\n",
        "        model.train()\n",
        "        for idx, batch in enumerate(tqdm(train_dataloader)):\n",
        "            inputs_k, targets_k = batch\n",
        "            inputs_v, targets_v = batch[inputs_k], batch[targets_k]#[0]\n",
        "            inputs_v = torch.stack([torch.stack(b_i) for b_i in inputs_v])\n",
        "            inputs_v = torch.transpose(inputs_v, 0, 2).to(torch.float32)\n",
        "            outputs = model(inputs_v.to(device))\n",
        "\n",
        "            tv_ls = targets_v.tolist()\n",
        "            for i in range(len(tv_ls)):\n",
        "              tv_ls[i] = int_to_lab[tv_ls[i]]\n",
        "            targets_v = torch.Tensor(tv_ls).long()\n",
        "\n",
        "            loss = criterion(outputs, targets_v.to(device))\n",
        "            loss.backward()\n",
        "\n",
        "            # === Gradient Accumulation === #\n",
        "            if ((idx + 1) % num_accumulate == 0) or (idx + 1 == len(train_dataloader)):\n",
        "                optimizer.step()\n",
        "                # scheduler.step_update(num_updates=num_updates)\n",
        "                optimizer.zero_grad()\n",
        "            # ============================= #\n",
        "\n",
        "            train_loss_epoch.append(loss.item())\n",
        "            train_preds += outputs.argmax(-1).detach().cpu().tolist()\n",
        "            train_targets += targets_v.tolist()\n",
        "\n",
        "        ### === Evaluation Loop === ###\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_dataloader):\n",
        "                inputs_k, targets_k = batch\n",
        "                inputs_v, targets_v = batch[inputs_k], batch[targets_k]#[0]\n",
        "                inputs_v = torch.stack([torch.stack(b_i) for b_i in inputs_v])\n",
        "                inputs_v = torch.transpose(inputs_v, 0, 2).to(torch.float32)\n",
        "                # inputs_v = torch.transpose(inputs_v, 1, 2)\n",
        "                outputs = model(inputs_v.to(device))\n",
        "\n",
        "                tv_ls = targets_v.tolist()\n",
        "                for i in range(len(tv_ls)):\n",
        "                  tv_ls[i] = int_to_lab[tv_ls[i]]\n",
        "                targets_v = torch.Tensor(tv_ls).long()\n",
        "\n",
        "                loss = criterion(outputs, targets_v.to(device))\n",
        "\n",
        "                # Log Values\n",
        "                val_loss_epoch.append(loss.item())\n",
        "                val_preds += outputs.argmax(-1).detach().cpu().tolist()\n",
        "                val_targets += targets_v.tolist()\n",
        "        ### ======================= ###\n",
        "\n",
        "        # Log Data\n",
        "        metric_train = metric.compute(predictions=train_preds, references=train_targets, average=\"macro\")[\"f1\"]\n",
        "        metric_val = metric.compute(predictions=val_preds, references=val_targets, average=\"macro\")[\"f1\"]\n",
        "\n",
        "        info[\"metric_train\"].append(metric_train)\n",
        "        info[\"metric_val\"].append(metric_val)\n",
        "\n",
        "        info[\"train_loss\"].append(np.average(train_loss_epoch))\n",
        "        info[\"val_loss\"].append(np.average(val_loss_epoch))\n",
        "\n",
        "        if metric_val > info[\"best_metric_val\"]:\n",
        "            print(\"New Best Score!\")\n",
        "            info[\"best_metric_val\"] = metric_val\n",
        "            torch.save(model, f\"checkpoint_fold{fold}.pt\")\n",
        "\n",
        "        print(info)\n",
        "        print(f\"Fold: {fold} | Epoch: {epoch} | Metric: {metric_val} | Training Loss: {np.average(train_loss_epoch)} | Validation Loss: {np.average(val_loss_epoch)}\")\n",
        "\n",
        "    # save all best metric val\n",
        "    all_eval_scores.append(info[\"best_metric_val\"])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp checkpoint*.pt drive/MyDrive/"
      ],
      "metadata": {
        "id": "X4d90YUGF6bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "enf8a_VEKszh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for fold in range(k_splits):\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    # load model\n",
        "    loaded_model = torch.load(f\"checkpoint_fold{fold}.pt\")\n",
        "    # Evaluation\n",
        "    loaded_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_dataloader):\n",
        "            inputs, targets = batch\n",
        "            outputs = loaded_model(inputs.to(device))\n",
        "\n",
        "            # Log Values\n",
        "            predictions += outputs.argmax(-1).detach().cpu().tolist()\n",
        "            references += targets.tolist()\n",
        "\n",
        "    print(f\"Fold: {fold}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(references, predictions)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "AVVi85DCKwpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "ZjEQQKEEAudx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJXovLcnAlWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzTLlaHv8uzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer HuggingFace"
      ],
      "metadata": {
        "id": "8ZskHm7ULePl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "TKchGUPBQ_uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_train)):\n",
        "  df_train.label[i] = df_train.label[i][0]  # thod list oak"
      ],
      "metadata": {
        "id": "kyHnzwYMTR8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, validation = train_test_split(df_train, test_size=0.25, random_state=888, stratify=df_train.label)\n",
        "train.shape, validation.shape"
      ],
      "metadata": {
        "id": "KYMVAI--REwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "gRyy7j9_SFm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "train_set = datasets.Dataset.from_dict(\n",
        "    {\n",
        "        \"chunk_seq\": train['chunk_seq'],\n",
        "        \"labels\": train['label']\n",
        "    }\n",
        ")\n",
        "\n",
        "val_set = datasets.Dataset.from_dict(\n",
        "    {\n",
        "        \"chunk_seq\": validation['chunk_seq'],\n",
        "        \"labels\": validation['label']\n",
        "    }\n",
        ")\n",
        "\n",
        "train_set, val_set"
      ],
      "metadata": {
        "id": "Gl3o625WUoCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()\n",
        "data_collator"
      ],
      "metadata": {
        "id": "cGZT9CxmNOTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "GIJFw-QxVZsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load Model\n",
        "model = Deformer(\n",
        "        num_chan=8,\n",
        "        num_time=1734,   # importantttt\n",
        "        temporal_kernel=13,  # using odd number to ensure \"same\" padding\n",
        "        num_kernel=64,\n",
        "        num_classes=3,\n",
        "        depth=4,\n",
        "        heads=16,\n",
        "        mlp_dim=16,\n",
        "        dim_head=16,\n",
        "        dropout=0.5\n",
        "    ).to(device)"
      ],
      "metadata": {
        "id": "vOyxyh2IWn5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"Expss4/art_eegDefomer\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_ratio=0.1,\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=10,\n",
        "    per_device_eval_batch_size=10,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "VKC5dn-iNpfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub('Expss4/art_eegDefomer')"
      ],
      "metadata": {
        "id": "RpvQAyarNpbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IwbpiUHPNpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KYLvgZST15D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZyoZH6XY7F_4",
        "M1WvsEsEDWS-",
        "ZG_ic4Sayn-n",
        "KyV8CIt8agOs",
        "6ThHvZH8r6NY",
        "8ZskHm7ULePl"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}