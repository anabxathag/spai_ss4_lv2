{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ggzi9eeujGFf",
        "QDs1kdlvpMDJ",
        "ne1Q9q9apO4R"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# load data"
      ],
      "metadata": {
        "id": "SgfIhXCog-D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "metadata": {
        "id": "mEuqw8bLjamo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ss4-exp-datasource/legalAct/legal-act-classification.zip"
      ],
      "metadata": {
        "id": "l4I-sqozjpOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "!unzip /content/legal-act-classification.zip -d dataset"
      ],
      "metadata": {
        "id": "BCU-gB86j3S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yETuCTLeHvT"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/content/dataset/train.csv\")\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test= pd.read_csv(\"/content/dataset/test.csv\")\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "wHDLo4_xg8lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = pd.read_csv('dataset/raw.csv')\n",
        "df_raw.head()"
      ],
      "metadata": {
        "id": "NVFOgOuXpBfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_committee = pd.read_csv('dataset/committee.csv')\n",
        "df_committee.head()"
      ],
      "metadata": {
        "id": "5rkiKqCRe-eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "Ggzi9eeujGFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "QDs1kdlvpMDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "id": "ombIjQa-kwCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "RIuuNbTsqSHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[df_train['legal_act'].isnull()]"
      ],
      "metadata": {
        "id": "ZzE_41l5zeOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['context'].value_counts()"
      ],
      "metadata": {
        "id": "1deZ2QmHkv_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['pattern'].value_counts()"
      ],
      "metadata": {
        "id": "sbwFWqRqnxXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['legal_act'].value_counts()"
      ],
      "metadata": {
        "id": "EVMRVzEHnxQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['condition'].value_counts()"
      ],
      "metadata": {
        "id": "RvVjv1Wdkvyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "ne1Q9q9apO4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "id": "lX9L0wFfqeY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['context'].value_counts()"
      ],
      "metadata": {
        "id": "bbCyWzJmpOwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['pattern'].value_counts()"
      ],
      "metadata": {
        "id": "GIxVB17jpOtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['legal_act'].value_counts()"
      ],
      "metadata": {
        "id": "tv3Qsg-GpOp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['condition'].value_counts()"
      ],
      "metadata": {
        "id": "FMYEhnGFpepn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "DKKayHqpvxbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process"
      ],
      "metadata": {
        "id": "bPwm7x8O4w3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['condition'] = df_train['condition'].fillna(\"ไม่มีเงื่อนไข\")"
      ],
      "metadata": {
        "id": "LirZiIqO5hby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['legal_act'] = df_train['legal_act'].fillna(\"ไม่มีการกระทำ\")"
      ],
      "metadata": {
        "id": "Ud3Fby-j5oqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['condition'] = df_test['condition'].fillna(\"ไม่มีเงื่อนไข\")"
      ],
      "metadata": {
        "id": "RsXf6cTY5xCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, validation = train_test_split(df_train, test_size=0.25, random_state=888, stratify=df_train.answer)\n",
        "train.shape, validation.shape"
      ],
      "metadata": {
        "id": "wsiA1pRWuwef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "pc3H3W3-weCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "train_set = datasets.Dataset.from_dict(\n",
        "    {\n",
        "        \"question\": train['question'],\n",
        "        \"context\": train['context'],\n",
        "        \"answer\": train['answer'],\n",
        "        # \"legal_act\": train['legal_act'],\n",
        "        # \"condition\": train['condition']\n",
        "    }\n",
        ")\n",
        "\n",
        "val_set = datasets.Dataset.from_dict(\n",
        "    {\n",
        "        \"question\": validation['question'],\n",
        "        \"context\": validation['context'],\n",
        "        \"answer\": validation['answer'],\n",
        "        # \"legal_act\": validation['legal_act'],\n",
        "        # \"condition\": validation['condition']\n",
        "    }\n",
        ")\n",
        "\n",
        "train_set, val_set"
      ],
      "metadata": {
        "id": "NiDy8JAtpelR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"studio-ousia/mluke-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"studio-ousia/mluke-base\")"
      ],
      "metadata": {
        "id": "hsfCutYz0gSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "id": "48nKRH817bqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[q.strip() for q in [\"นางสาวนภัสกร แซ่เนี้ยว ลงลายมือชื่อ เว้นแต่การทำธุรกรรมทางการเงินให้นางสาวนภัสกร แซ่เนี้ยว และ นายอภิวิชษ์ สายภู่ ลงลายมือชื่อร่วมกัน\"]]"
      ],
      "metadata": {
        "id": "3pXLNEaZ92-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    contexts = [c.strip() for c in examples[\"context\"]]\n",
        "    inputs = tokenizer(\n",
        "        contexts,\n",
        "        examples[\"question\"],\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    inputs[\"labels\"] = examples[\"answer\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_train = train_set.map(preprocess_function, batched=True, remove_columns=train_set.column_names)\n",
        "tokenized_validation = val_set.map(preprocess_function, batched=True, remove_columns=val_set.column_names)\n",
        "tokenized_train"
      ],
      "metadata": {
        "id": "JPr9BSoNxXl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()\n",
        "data_collator"
      ],
      "metadata": {
        "id": "lthI7uSo19bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "2EMmPtSn47ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "OLlaqyIZ6ojy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "FAuZQIZy7IHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"mruk_law\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_validation,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "T87uA9VI46_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "-kNZQn_h468b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "DavVNXCg55TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "_KRSCuPsDWh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nattawatWe/legal_exp\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"nattawatWe/legal_exp\", device_map=\"cuda:0\")"
      ],
      "metadata": {
        "id": "Tzcrw_IU6m80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_set[0]"
      ],
      "metadata": {
        "id": "SmmPW7ou5Oyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    contexts = [c.strip() for c in examples[\"context\"]]\n",
        "    inputs = tokenizer(\n",
        "        contexts,\n",
        "        examples[\"question\"],\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    inputs[\"labels\"] = examples[\"answer\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_validation = val_set.map(preprocess_function, batched=True, remove_columns=val_set.column_names)\n",
        "tokenized_validation"
      ],
      "metadata": {
        "id": "9Y2Cw3pY5OvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "data_collator = default_data_collator\n",
        "validation_dataloader = DataLoader(tokenized_validation, collate_fn=data_collator, batch_size=8)\n",
        "\n",
        "predictions = []\n",
        "for batch in tqdm(validation_dataloader):\n",
        "    with torch.no_grad():\n",
        "        inputs = {key: batch[key].to(model.device) for key in batch}\n",
        "        outputs = model(**inputs)\n",
        "    predicted_class = torch.argmax(outputs.logits, dim=1)\n",
        "    predictions.extend(predicted_class.tolist())\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "3B4t3se16m5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "\n",
        "for i in range(len(validation[:]['answer'])):\n",
        "    if val_set[i]['answer'] == predictions[i]:\n",
        "        TP += 1\n",
        "    else:\n",
        "        FP += 1\n",
        "        FN += 1\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)"
      ],
      "metadata": {
        "id": "eajlaGUp5Cna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "Bt3UEa8k5YZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "test = datasets.Dataset.from_dict(\n",
        "    {\n",
        "        \"question\": df_test['question'],\n",
        "        \"context\": df_test['context'],\n",
        "    }\n",
        ")\n",
        "\n",
        "test"
      ],
      "metadata": {
        "id": "OoONXEVj5Cjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    contexts = [c.strip() for c in examples[\"context\"]]\n",
        "    inputs = tokenizer(\n",
        "        contexts,\n",
        "        examples[\"question\"],\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "tokenized_test = test.map(preprocess_function, batched=True, remove_columns=test.column_names)\n",
        "tokenized_test"
      ],
      "metadata": {
        "id": "KRzhWkTV5QKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "x2zEjGDc5QGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = default_data_collator\n",
        "test_dataloader = DataLoader(tokenized_test, collate_fn=data_collator, batch_size=64)\n",
        "\n",
        "predictions = []\n",
        "for batch in tqdm(test_dataloader):\n",
        "    with torch.no_grad():\n",
        "        inputs = {key: batch[key].to(model.device) for key in batch}\n",
        "        outputs = model(**inputs)\n",
        "    predicted_class = torch.argmax(outputs.logits, dim=1)\n",
        "    predictions.extend(predicted_class.tolist())\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "6hXUc6O1g8qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/dataset/sample_submission.csv')\n",
        "submission"
      ],
      "metadata": {
        "id": "zirvguoC5dGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['answer'][3:] = predictions[3:]\n",
        "submission"
      ],
      "metadata": {
        "id": "XyIK55RD5q3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['answer'] = submission['answer'].astype(int)"
      ],
      "metadata": {
        "id": "FftLwWocLUgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['answer'] = submission['answer'].astype(str)"
      ],
      "metadata": {
        "id": "B9fuwr9FLbxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "NZRJam24LfoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('the_art_of_state.csv',index = False)"
      ],
      "metadata": {
        "id": "8-GOLZMF5u63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "flNu2wjj5dDJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}