{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18dn2kDqEckDqFphWiUbyqLpo4scIB9r_","timestamp":1716187906089}],"toc_visible":true,"machine_shape":"hm","collapsed_sections":["7Fgr3vWXmChe","HejIGkTnY2bZ"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup kaggle api"],"metadata":{"id":"JzXo_C9CfqGS"}},{"cell_type":"code","source":["\n","# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n","# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n","# THEN FEEL FREE TO DELETE THIS CELL.\n","# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n","# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n","# NOTEBOOK.\n","\n","import os\n","import sys\n","from tempfile import NamedTemporaryFile\n","from urllib.request import urlopen\n","from urllib.parse import unquote, urlparse\n","from urllib.error import HTTPError\n","from zipfile import ZipFile\n","import tarfile\n","import shutil\n","\n","CHUNK_SIZE = 40960\n","DATA_SOURCE_MAPPING = 'home-credit-credit-risk-model-stability:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F50160%2F7921029%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240521%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240521T081657Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D194228c8056848eed92d0cde88d36347021113f50d8e6137369b3845b15399442b43805f970378239656c056352f616f80bf2a2f64fed490200a44684732db8336bf1d600598be7ff87748422d0b64c49ffe73a61d6fc51e7e7df0ed14028840b129b0194fcb79dd530253d7c8ecfaa18f217f00dd3b6fad9d5bdd5b250936ab874f6c08438b4da3de28708892f1da174d7d204f4aeba1d566fd4598d04d22139240d6414ac251e6a30085690089c5dac0c7e18ee34434ff8f9ee23423cb8229cd4ada320abec8754daccda1d8a329b7e68ddfe4eef7b4532dd3fe206a31b8c06d28779f59e330a141a0401d25ce2681eb438edf181603dc43f627d2be83f9a8,homecredit-models-public/other/lgb/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F27710%2F33095%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240521%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240521T081657Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D372798d7ba35bce2fbf06da9879b814f524d215bdf96d7b939d660d0214f4e8599c84aa04d8cc130514d94c49a40a952cffc3de942db9d827e197bfafdfeaa5b868e2aa575abb66ac2f8950ed444f8b524560f8d36012950fc157ece79b704a88b2d708a3d7752900c3a5f28e7ea9efaca7a3817ea361332608cbbc51ae6d833c104e8961db593083b671592a4a170f2299e3a1b449bcd0da67b4ff65c0bbff5658d26426ff878f0db24746bd7ff23212ec9439677819277b2bfe0a75f14cf1c9ed372164727076408542a35d08efb56ff0b3eea4f1b2f1f1aeb93c1fa79c3d5cdea0422fe3c044f3c1567a4a2577214084c06d8b05250bbbcb5b50561b04ab9,homecredit-models-public/other/cat/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F27711%2F33096%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240521%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240521T081657Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D13ccd3ccc303d419097616bd99eac50013654df7a6e1f3fcd4e003cadbbb1f288a774bfcc96c7a88fae374a8f079fa57eb2442e195732cb66b1efafe972f6c8a50ec21e7f5b964d589c468e7e7fb2290a598f22833d67b163c0474b06084a063318986df235e7c28f82a12e700c489a6d27c5556e7714c9a99a50ea232c2d0cf3baf807c9137571a3c021746555a66a243fa92f4f5153e898ee5eda7d23c453a67a8678204c59c9dce3e4253d73a0eeb09834ff02df2c0b62beec5adf106d510614197480e11a2830a5cebd8221f76cc8d607db6846bb334483f4b592a7a8023ec9bc245d797916bb0334bd1b9b1db418740a266644b645fcb3bb613d69b5a58'\n","\n","KAGGLE_INPUT_PATH='/kaggle/input'\n","KAGGLE_WORKING_PATH='/kaggle/working'\n","KAGGLE_SYMLINK='kaggle'\n","\n","!umount /kaggle/input/ 2> /dev/null\n","shutil.rmtree('/kaggle/input', ignore_errors=True)\n","os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n","os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n","\n","try:\n","  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n","except FileExistsError:\n","  pass\n","try:\n","  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n","except FileExistsError:\n","  pass\n","\n","for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n","    directory, download_url_encoded = data_source_mapping.split(':')\n","    download_url = unquote(download_url_encoded)\n","    filename = urlparse(download_url).path\n","    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n","    try:\n","        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n","            total_length = fileres.headers['content-length']\n","            print(f'Downloading {directory}, {total_length} bytes compressed')\n","            dl = 0\n","            data = fileres.read(CHUNK_SIZE)\n","            while len(data) > 0:\n","                dl += len(data)\n","                tfile.write(data)\n","                done = int(50 * dl / int(total_length))\n","                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n","                sys.stdout.flush()\n","                data = fileres.read(CHUNK_SIZE)\n","            if filename.endswith('.zip'):\n","              with ZipFile(tfile) as zfile:\n","                zfile.extractall(destination_path)\n","            else:\n","              with tarfile.open(tfile.name) as tarfile:\n","                tarfile.extractall(destination_path)\n","            print(f'\\nDownloaded and uncompressed: {directory}')\n","    except HTTPError as e:\n","        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n","        continue\n","    except OSError as e:\n","        print(f'Failed to load {download_url} to path {destination_path}')\n","        continue\n","\n","print('Data source import complete.')"],"metadata":{"id":"Ju5qmZaUOpFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJ2oRCiFfbGr"},"outputs":[],"source":["from google.colab import userdata\n","username = userdata.get('KAGGLE_USER')\n","key = userdata.get('KAGGLE_KEY')\n","# Echo the credentials into the kaggle.json file\n","!mkdir -p ~/.kaggle\n","!echo '{{\"username\":\"{username}\",\"key\":\"{key}\"}}' > ~/.kaggle/kaggle.json\n","!chmod 600 /root/.kaggle/kaggle.json"]},{"cell_type":"markdown","source":["[Home Credit - Credit Risk Model Stability](https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/overview)"],"metadata":{"id":"YRUSZFhcf9Ug"}},{"cell_type":"code","source":["# Download dataset\n","!kaggle competitions download -c home-credit-credit-risk-model-stability\n","!unzip /content/home-credit-credit-risk-model-stability.zip && rm -rf /content/home-credit-credit-risk-model-stability.zip"],"metadata":{"id":"5nATNKG6fwt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv /content/sample_submission.csv /content/sample_sub_og.csv"],"metadata":{"id":"1NiIQClNVzl4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[Home Credit - Credit Risk Modeling](https://www.kaggle.com/competitions/home-credit-credit-risk-modeling/overview)"],"metadata":{"id":"-gn7C6EpESB8"}},{"cell_type":"code","source":["# Download dataset\n","!kaggle competitions download -c home-credit-credit-risk-modeling\n","!unzip /content/home-credit-credit-risk-modeling.zip && rm -rf /content/home-credit-credit-risk-modeling.zip"],"metadata":{"id":"oL3mm_wVDWKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !mv /content/sample_submission.csv /content/sample_sub_hack.csv"],"metadata":{"id":"6IbGUFmPWPtn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv /content/test.parquet /content/test_dataset/transformed"],"metadata":{"id":"AJ62r9HOWWGm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 0.361"],"metadata":{"id":"3TY5nJoZIkYe"}},{"cell_type":"code","source":["import sys  # System-specific parameters and functions\n","import subprocess  # Spawn new processes, connect to their input/output/error pipes, and obtain their return codes\n","import os  # Operating system dependent functionality\n","import gc  # Garbage Collector interface\n","from pathlib import Path  # Object-oriented filesystem paths\n","from glob import glob  # Unix style pathname pattern expansion\n","\n","import numpy as np  # Fundamental package for scientific computing with Python\n","import pandas as pd  # Powerful data structures for data manipulation and analysis\n","import polars as pl  # Fast DataFrame library implemented in Rust\n","\n","from datetime import datetime  # Basic date and time types\n","import seaborn as sns  # Statistical data visualization\n","import matplotlib.pyplot as plt  # MATLAB-like plotting framework\n","\n","import joblib  # Save and load Python objects\n","\n","import warnings  # Warning control\n","\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","\n","\n","warnings.filterwarnings('ignore')  # Ignore warnings"],"metadata":{"id":"xIxpX1vZgMC9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train_base = pd.read_csv('/content/csv_files/train/train_base.csv')\n","\n","display(df_train_base)"],"metadata":{"id":"Yw6uSy6qj2tx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","df_train_static= pd.read_csv('/content/csv_files/train/train_static_0_0.csv')\n","display(df_train_static)"],"metadata":{"id":"Lx1TmOgAkCHr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","pl_train_static = pl.read_csv('/content/csv_files/train/train_static_0_0.csv')\n","display(pl_train_static)"],"metadata":{"id":"Md_od9gVkNJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del df_train_static, pl_train_static, df_train_base"],"metadata":{"id":"jTN5V3BVt_Jv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc  # Garbage Collector interface\n","gc.collect()"],"metadata":{"id":"_BpVH1Rr-lgp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ðŸ› ï¸ðŸ“Š **Pipeline for Data Preprocessing**\n","Let's create a class named Pipeline containing methods to preprocess data using Pandas and Pipelines.\n","\n","#### **set_table_dtypes(df)**\n","\n","- This method iterates through each column in the DataFrame (df) and converts the data types based on certain conditions.\n","- If the column name is one of [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"], it converts the column to Int64.\n","- If the column name is \"date_decision\", it converts the column to Date.\n","- If the last character of the column name is \"P\" or \"A\", it converts the column to Float64.\n","- If the last character of the column name is \"M\", it converts the column to String.\n","- If the last character of the column name is \"D\", it converts the column to Date.\n","Finally, it returns the DataFrame with modified data types.\n"],"metadata":{"id":"dMrEQ3iKoqyN"}},{"cell_type":"code","source":["def set_table_dtypes(df):\n","    for col in df.columns:\n","        if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n","            df = df.with_columns(pl.col(col).cast(pl.Int64))\n","        elif col in [\"date_decision\"]:\n","            df = df.with_columns(pl.col(col).cast(pl.Date))\n","        elif col[-1] in (\"P\", \"A\"):\n","            df = df.with_columns(pl.col(col).cast(pl.Float64))\n","        elif col[-1] in (\"D\",):\n","            df = df.with_columns(pl.col(col).cast(pl.Date))\n","    return df\n","\n","def convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n","    for col in df.columns:\n","        if df[col].dtype.name in ['object', 'string']:\n","            df[col] = df[col].astype(\"string\").astype('category')\n","            current_categories = df[col].cat.categories\n","            new_categories = current_categories.to_list() + [\"Unknown\"]\n","            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n","            df[col] = df[col].astype(new_dtype)\n","    return df\n"],"metadata":{"id":"DX-59Gk1m1J4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataPath = os.getcwd()+'/'\n","dataPath"],"metadata":{"id":"-K1s5OLRuOEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_basetable = pl.read_csv(dataPath + \"csv_files/train/train_base.csv\")\n","train_static = pl.concat(\n","    [\n","        pl.read_csv(dataPath + \"csv_files/train/train_static_0_0.csv\").pipe(set_table_dtypes),\n","        pl.read_csv(dataPath + \"csv_files/train/train_static_0_1.csv\").pipe(set_table_dtypes),\n","    ],\n","    how=\"vertical_relaxed\",\n",")\n","train_static_cb = pl.read_csv(dataPath + \"csv_files/train/train_static_cb_0.csv\").pipe(set_table_dtypes)\n","train_person_1 = pl.read_csv(dataPath + \"csv_files/train/train_person_1.csv\").pipe(set_table_dtypes)\n","train_credit_bureau_b_2 = pl.read_csv(dataPath + \"csv_files/train/train_credit_bureau_b_2.csv\").pipe(set_table_dtypes)"],"metadata":{"id":"z23aiMZTt84O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_basetable = pl.read_csv(dataPath + \"csv_files/test/test_base.csv\")\n","test_static = pl.concat(\n","    [\n","        pl.read_csv(dataPath + \"csv_files/test/test_static_0_0.csv\").pipe(set_table_dtypes),\n","        pl.read_csv(dataPath + \"csv_files/test/test_static_0_1.csv\").pipe(set_table_dtypes),\n","        pl.read_csv(dataPath + \"csv_files/test/test_static_0_2.csv\").pipe(set_table_dtypes),\n","    ],\n","    how=\"vertical_relaxed\",\n",")\n","test_static_cb = pl.read_csv(dataPath + \"csv_files/test/test_static_cb_0.csv\").pipe(set_table_dtypes)\n","test_person_1 = pl.read_csv(dataPath + \"csv_files/test/test_person_1.csv\").pipe(set_table_dtypes)\n","test_credit_bureau_b_2 = pl.read_csv(dataPath + \"csv_files/test/test_credit_bureau_b_2.csv\").pipe(set_table_dtypes)"],"metadata":{"id":"vPLbSu53vqp9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_static.head()"],"metadata":{"id":"bqaH8elbB7JU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(test_static.columns)"],"metadata":{"id":"Ff3iUfslCwQ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Feature engineering**\n","In this part, we can see a simple example of joining tables via case_id. Here the loading and joining is done with polars library. Polars library is blazingly fast and has much smaller memory footprint than pandas."],"metadata":{"id":"dh46f52-vzAf"}},{"cell_type":"code","source":["# We need to use aggregation functions in tables with depth > 1, so tables that contain num_group1 column or\n","# also num_group2 column.\n","train_person_1_feats_1 = train_person_1.group_by(\"case_id\").agg(\n","    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n","    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",")\n","\n","# Here num_group1=0 has special meaning, it is the person who applied for the loan.\n","train_person_1_feats_2 = train_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n","    pl.col(\"num_group1\") == 0\n",").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n","\n","# Here we have num_goup1 and num_group2, so we need to aggregate again.\n","train_credit_bureau_b_2_feats = train_credit_bureau_b_2.group_by(\"case_id\").agg(\n","    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n","    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",")\n","\n","# We will process in this examples only A-type and M-type columns, so we need to select them.\n","selected_static_cols = []\n","for col in train_static.columns:\n","    if col[-1] in (\"A\", \"M\"):\n","        selected_static_cols.append(col)\n","print(selected_static_cols)\n","\n","selected_static_cb_cols = []\n","for col in train_static_cb.columns:\n","    if col[-1] in (\"A\", \"M\"):\n","        selected_static_cb_cols.append(col)\n","print(selected_static_cb_cols)\n","\n","# Join all tables together.\n","data = train_basetable.join(\n","    train_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",").join(\n","    train_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",").join(\n","    train_person_1_feats_1, how=\"left\", on=\"case_id\"\n",").join(\n","    train_person_1_feats_2, how=\"left\", on=\"case_id\"\n",").join(\n","    train_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",")"],"metadata":{"id":"uvHS5cBsvwAZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_person_1_feats_1 = test_person_1.group_by(\"case_id\").agg(\n","    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n","    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",")\n","\n","test_person_1_feats_2 = test_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n","    pl.col(\"num_group1\") == 0\n",").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n","\n","test_credit_bureau_b_2_feats = test_credit_bureau_b_2.group_by(\"case_id\").agg(\n","    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n","    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",")\n","\n","data_submission = test_basetable.join(\n","    test_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",").join(\n","    test_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",").join(\n","    test_person_1_feats_1, how=\"left\", on=\"case_id\"\n",").join(\n","    test_person_1_feats_2, how=\"left\", on=\"case_id\"\n",").join(\n","    test_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",")"],"metadata":{"id":"lLGk94SCwKWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["case_ids = data[\"case_id\"].unique().shuffle(seed=1)\n","case_ids_train, case_ids_test = train_test_split(case_ids, train_size=0.6, random_state=1)\n","case_ids_valid, case_ids_test = train_test_split(case_ids_test, train_size=0.5, random_state=1)\n","\n","cols_pred = []\n","for col in data.columns:\n","    if col[-1].isupper() and col[:-1].islower():\n","        cols_pred.append(col)\n","\n","print(cols_pred)"],"metadata":{"id":"p6EZPfEmwXHd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def from_polars_to_pandas(case_ids: pl.DataFrame) -> pl.DataFrame:\n","    return (\n","        data.filter(pl.col(\"case_id\").is_in(case_ids))[[\"case_id\", \"WEEK_NUM\", \"target\"]].to_pandas(),\n","        data.filter(pl.col(\"case_id\").is_in(case_ids))[cols_pred].to_pandas(),\n","        data.filter(pl.col(\"case_id\").is_in(case_ids))[\"target\"].to_pandas()\n","    )"],"metadata":{"id":"71Z4ZVS5wgrN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **reduce_mem_usage(df)**\n","\n","- Input:\n","  - df: Input DataFrame.\n","- Output: Returns the DataFrame with reduced memory usage.\n","- Process:\n","  - Calculates the initial memory usage of the DataFrame (start_mem) using df.memory_usage().\n","  - Iterates through each column of the DataFrame:\n","   - Checks if the column type is a category. If so, skips to the next column.\n","   - For non-category columns:\n","     - Determines the minimum and maximum values of the column (c_min and c_max).\n","     - If the column type is integer:\n","       - Checks if the data can be fit into int8, int16, int32, or int64 and converts the column type accordingly.\n","     - If the column type is float:\n","       - Checks if the data can be fit into float16, float32, or float64 and converts the column type accordingly.\n","     - If the column type is object (string), it skips the conversion.\n","  - Calculates the final memory usage of the DataFrame (end_mem) after the modifications.\n","- Returns the DataFrame with reduced memory usage.\n","\n","#### Study Sources\n","- Optimizing memory usage in Pandas: [Optimizing Memory Usage in Pandas](https://www.dataquest.io/blog/pandas-big-data/)\n","- Understanding data types and memory in Pandas: [Pandas Data Types and Memory Usage](https://pbpython.com/pandas_dtypes.html)\n","- Data type conversion in NumPy: [NumPy Data Types](https://numpy.org/doc/stable/reference/arrays.scalars.html#arrays-scalars-built-in)"],"metadata":{"id":"AJd-eTUa1NXO"}},{"cell_type":"code","source":["def reduce_mem_usage(df):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.\n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","\n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        if str(col_type)==\"category\":\n","            continue\n","\n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            continue\n","    end_mem = df.memory_usage().sum() / 1024**2\n","\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","    return df"],"metadata":{"id":"SO1DKNv21IpN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_train, X_train, y_train = from_polars_to_pandas(case_ids_train)\n","base_valid, X_valid, y_valid = from_polars_to_pandas(case_ids_valid)\n","base_test, X_test, y_test = from_polars_to_pandas(case_ids_test)\n","\n","for df in [X_train, X_valid, X_test]:\n","    df = convert_strings(df)\n","    df = reduce_mem_usage(df)"],"metadata":{"id":"3zJOTbYgxNBD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Train: {X_train.shape}\")\n","print(f\"Valid: {X_valid.shape}\")\n","print(f\"Test: {X_test.shape}\")"],"metadata":{"id":"SR2RiHJRxUXp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lgb_train = lgb.Dataset(X_train, label=y_train)\n","lgb_valid = lgb.Dataset(X_valid, label=y_valid, reference=lgb_train)\n","\n","params = {\n","    \"boosting_type\": \"gbdt\",\n","    \"objective\": \"binary\",\n","    \"metric\": \"auc\",\n","    \"max_depth\": 3,\n","    \"num_leaves\": 31,\n","    \"learning_rate\": 0.05,\n","    \"feature_fraction\": 0.9,\n","    \"bagging_fraction\": 0.8,\n","    \"bagging_freq\": 5,\n","    \"n_estimators\": 1000,\n","    \"verbose\": -1,\n","}\n","\n","gbm = lgb.train(\n","    params,\n","    lgb_train,\n","    valid_sets=lgb_valid,\n","    callbacks=[lgb.log_evaluation(50), lgb.early_stopping(10)]\n",")"],"metadata":{"id":"67wV87caxft4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for base, X in [(base_train, X_train), (base_valid, X_valid), (base_test, X_test)]:\n","    y_pred = gbm.predict(X, num_iteration=gbm.best_iteration)\n","    base[\"score\"] = y_pred\n","\n","print(f'The AUC score on the train set is: {roc_auc_score(base_train[\"target\"], base_train[\"score\"])}')\n","print(f'The AUC score on the valid set is: {roc_auc_score(base_valid[\"target\"], base_valid[\"score\"])}')\n","print(f'The AUC score on the test set is: {roc_auc_score(base_test[\"target\"], base_test[\"score\"])}')"],"metadata":{"id":"RJSg6Lx7xrn3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n","    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n","        .sort_values(\"WEEK_NUM\")\\\n","        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n","        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n","\n","    x = np.arange(len(gini_in_time))\n","    y = gini_in_time\n","    a, b = np.polyfit(x, y, 1)\n","    y_hat = a*x + b\n","    residuals = y - y_hat\n","    res_std = np.std(residuals)\n","    avg_gini = np.mean(gini_in_time)\n","    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std\n","\n","stability_score_train = gini_stability(base_train)\n","stability_score_valid = gini_stability(base_valid)\n","stability_score_test = gini_stability(base_test)\n","\n","print(f'The stability score on the train set is: {stability_score_train}')\n","print(f'The stability score on the valid set is: {stability_score_valid}')\n","print(f'The stability score on the test set is: {stability_score_test}')"],"metadata":{"id":"XvUXm4UYxu5G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GWPptDQHNLE9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_submission = data_submission[cols_pred].to_pandas()\n","X_submission = convert_strings(X_submission)\n","categorical_cols = X_train.select_dtypes(include=['category']).columns\n","\n","for col in categorical_cols:\n","    train_categories = set(X_train[col].cat.categories)\n","    submission_categories = set(X_submission[col].cat.categories)\n","    new_categories = submission_categories - train_categories\n","    X_submission.loc[X_submission[col].isin(new_categories), col] = \"Unknown\"\n","    new_dtype = pd.CategoricalDtype(categories=train_categories, ordered=True)\n","    X_train[col] = X_train[col].astype(new_dtype)\n","    X_submission[col] = X_submission[col].astype(new_dtype)\n","\n","y_submission_pred = gbm.predict(X_submission, num_iteration=gbm.best_iteration)"],"metadata":{"id":"MB6nzguAxxie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_submission_pred"],"metadata":{"id":"JsgB0MK2E8xl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_submission"],"metadata":{"id":"0e6vxRaiFJ_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission = pd.DataFrame({\n","    \"case_id\": data_submission[\"case_id\"].to_numpy(),\n","    \"score\": y_submission_pred\n","}).set_index('case_id')\n","submission.to_csv(\"./submission.csv\")"],"metadata":{"id":"e86BgrHfx2y7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission"],"metadata":{"id":"HSplQwP1x4CY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 0.653"],"metadata":{"id":"7Kx52nXdItRw"}},{"cell_type":"code","source":["import sys  # System-specific parameters and functions\n","import subprocess  # Spawn new processes, connect to their input/output/error pipes, and obtain their return codes\n","import os  # Operating system dependent functionality\n","import gc  # Garbage Collector interface\n","from pathlib import Path  # Object-oriented filesystem paths\n","from glob import glob  # Unix style pathname pattern expansion\n","\n","import numpy as np  # Fundamental package for scientific computing with Python\n","import pandas as pd  # Powerful data structures for data manipulation and analysis\n","import polars as pl  # Fast DataFrame library implemented in Rust\n","\n","from datetime import datetime  # Basic date and time types\n","import seaborn as sns  # Statistical data visualization\n","import matplotlib.pyplot as plt  # MATLAB-like plotting framework\n","\n","import joblib  # Save and load Python objects\n","\n","import warnings  # Warning control\n","warnings.filterwarnings('ignore')  # Ignore warnings\n","\n","from sklearn.base import BaseEstimator, RegressorMixin  # Base classes for all estimators in scikit-learn\n","from sklearn.metrics import roc_auc_score  # ROC AUC score\n","import lightgbm as lgb  # LightGBM: Gradient boosting framework\n","from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold  # Cross-validation strategies\n","from imblearn.over_sampling import SMOTE  # Oversampling technique for imbalanced datasets\n","from sklearn.preprocessing import OrdinalEncoder  # Encode categorical features as an integer array\n","from sklearn.impute import KNNImputer  # Imputation for completing missing values using k-Nearest Neighbors"],"metadata":{"id":"m0DpnAPrIs8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install catboost"],"metadata":{"id":"J2-V6Ed94uhU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pipeline for Data Preprocessing"],"metadata":{"id":"pAgyIe5xKzgM"}},{"cell_type":"code","source":["class Pipeline:\n","\n","    def set_table_dtypes(df):\n","        for col in df.columns:\n","            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Int64))\n","            elif col in [\"date_decision\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","            elif col[-1] in (\"P\", \"A\"):\n","                df = df.with_columns(pl.col(col).cast(pl.Float64))\n","            elif col[-1] in (\"M\",):\n","                df = df.with_columns(pl.col(col).cast(pl.Utf8)) # String\n","            elif col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","        return df\n","\n","    def handle_dates(df):\n","        for col in df.columns:\n","            if col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))  #!!?\n","                df = df.with_columns(pl.col(col).dt.total_days()) # t - t-1\n","        df = df.drop(\"date_decision\", \"MONTH\")\n","        return df\n","\n","    def filter_cols(df):\n","        # for col in df.columns:\n","        #     if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n","        #         isnull = df[col].is_null().mean()\n","        #         if isnull > 0.7:\n","        #             df = df.drop(col)\n","\n","        for col in df.columns:\n","            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.Utf8):\n","                freq = df[col].n_unique()\n","                if (freq == 1) | (freq > 200):\n","                    df = df.drop(col)\n","\n","        return df"],"metadata":{"id":"D6gQJbdnJ4Sz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Aggregator:\n","    #Please add or subtract features yourself, be aware that too many features will take up too much space.\n","    def num_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","        return expr_max\n","\n","    def date_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"D\")]\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","        return  expr_max\n","\n","    def str_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","        return  expr_max\n","\n","    def other_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","        return  expr_max\n","\n","    def count_expr(df):\n","        cols = [col for col in df.columns if \"num_group\" in col]\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","        return  expr_max\n","\n","    def get_exprs(df):\n","        exprs = Aggregator.num_expr(df) + \\\n","                Aggregator.date_expr(df) + \\\n","                Aggregator.str_expr(df) + \\\n","                Aggregator.other_expr(df) + \\\n","                Aggregator.count_expr(df)\n","\n","        return exprs"],"metadata":{"id":"71jvOXZ2J4MN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_file(path, depth=None):\n","    df = pl.read_parquet(path)\n","    df = df.pipe(Pipeline.set_table_dtypes)\n","    if depth in [1,2]:\n","        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","    return df\n","\n","def read_files(regex_path, depth=None):\n","    chunks = []\n","\n","    for path in glob(str(regex_path)):\n","        df = pl.read_parquet(path)\n","        df = df.pipe(Pipeline.set_table_dtypes)\n","        if depth in [1, 2]:\n","            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","        chunks.append(df)\n","\n","    df = pl.concat(chunks, how=\"vertical_relaxed\")\n","    df = df.unique(subset=[\"case_id\"])\n","    return df\n","\n","def feature_eng(df_base, depth_0, depth_1, depth_2):\n","    df_base = (\n","        df_base\n","        .with_columns(\n","            month_decision = pl.col(\"date_decision\").dt.month(),\n","            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n","        )\n","    )\n","    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n","        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n","    df_base = df_base.pipe(Pipeline.handle_dates)\n","    return df_base\n","\n","def to_pandas(df_data, cat_cols=None):\n","    df_data = df_data.to_pandas()\n","    if cat_cols is None:\n","        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n","    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n","    return df_data, cat_cols"],"metadata":{"id":"dl50On0aeTyc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reduce_mem_usage(df):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.\n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n","\n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        if str(col_type)==\"category\":\n","            continue\n","\n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            continue\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","\n","    return df"],"metadata":{"id":"VsBolFIRPwYX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Preprocessing and Feature Engineering"],"metadata":{"id":"WlLT5Ml9XOwv"}},{"cell_type":"code","source":["ROOT_og = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n","\n","TRAIN_DIR = ROOT_og / \"parquet_files\" / \"train\"\n","# TRAIN_DIR = \"/content/parquet_files/train\""],"metadata":{"id":"r1QVI_ZnPwVN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_store = {\n","    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n","    \"depth_0\": [\n","        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n","        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n","    ],\n","    \"depth_1\": [\n","        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n","        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n","        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n","        # read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n","    ],\n","    \"depth_2\": [\n","        read_file(TRAIN_DIR / \"train_applprev_2.parquet\", 2),\n","        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n","        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n","        read_file(TRAIN_DIR / \"train_person_2.parquet\", 2),\n","    ]\n","}\n"],"metadata":{"id":"sfRD1QrxIs4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = feature_eng(**data_store)\n","print(len(df_train.columns))\n","\n","del data_store\n","gc.collect()\n","\n","df_train = df_train.pipe(Pipeline.filter_cols)\n","print(len(df_train.columns))\n","\n","df_train, cat_cols = to_pandas(df_train)\n","print(len(df_train.columns), len(cat_cols))\n","\n","df_train = reduce_mem_usage(df_train)\n","# nums = df_train.select_dtypes(exclude='category').columns\n","df_train"],"metadata":{"id":"f4msC-X4XccZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# nans_df = df_train[nums].isna()\n","# print(len(nans_df.columns))\n","\n","# nans_groups={}\n","# for col in nums:\n","#     cur_group = nans_df[col].sum()\n","#     try:\n","#         nans_groups[cur_group].append(col)\n","#     except:\n","#         nans_groups[cur_group]=[col]\n","\n","encoder = OrdinalEncoder()\n","# del nans_df; x=gc.collect()\n","# print(nans_groups)\n","df_train[cat_cols] = encoder.fit_transform(df_train[cat_cols])\n","df_train"],"metadata":{"id":"5Oof4ArefnJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df_train[df_train['target'] == 1]), len(df_train[df_train['target'] == 0])"],"metadata":{"id":"0d0kuQrOh69L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- downsampling"],"metadata":{"id":"8gfiQgjWib5i"}},{"cell_type":"code","source":["df_majority = df_train[df_train['target'] == 0]\n","df_minority = df_train[df_train['target'] == 1]\n","n_minority = len(df_minority)\n","df_majority_undersampled = df_majority.sample(n=n_minority, random_state=42)\n","df_train_balanced = pd.concat([df_majority_undersampled, df_minority])\n","df_train_balanced = df_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n","df_train_balanced"],"metadata":{"id":"vfB9csggfnHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df_train_balanced[df_train_balanced['target'] == 1]), len(df_train_balanced[df_train_balanced['target'] == 0])"],"metadata":{"id":"cjE0KD-8fm3C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### drop columns that not have in test (no need to run)"],"metadata":{"id":"7Fgr3vWXmChe"}},{"cell_type":"code","source":["cols_drop = ['max_empl_employedtotal_800L', 'max_empl_industry_691L', 'max_relationshiptoclient_415T', 'max_relationshiptoclient_642T', 'max_remitter_829L']"],"metadata":{"id":"sFoNWjtxlYhZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train_balanced = df_train_balanced.drop(columns=cols_drop)"],"metadata":{"id":"H0NSMM9elUxK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df_train_balanced.columns)"],"metadata":{"id":"WMmekJGFvcGV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(cat_cols))\n","for ele in cols_drop:\n","  cat_cols.remove(ele)\n","print(len(cat_cols))"],"metadata":{"id":"9wBG1J9MmCAZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reduce Group Columns"],"metadata":{"id":"HejIGkTnY2bZ"}},{"cell_type":"code","source":["def reduce_group(grps):\n","    use = []\n","    for g in grps:\n","        mx = 0; vx = g[0]\n","        for gg in g:\n","            n = df_train[gg].nunique()\n","            if n>mx:\n","                mx = n\n","                vx = gg\n","        use.append(vx)\n","    return use\n","\n"],"metadata":{"id":"Ucct9t-ajgGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def group_columns_by_correlation(matrix, threshold=0.8):\n","    correlation_matrix = matrix.corr()\n","    groups = []\n","    remaining_cols = list(matrix.columns)\n","    while remaining_cols:\n","        col = remaining_cols.pop(0)\n","        group = [col]\n","        correlated_cols = [col]\n","        for c in remaining_cols:\n","            if correlation_matrix.loc[col, c] >= threshold:\n","                group.append(c)\n","                correlated_cols.append(c)\n","        groups.append(group)\n","        remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n","\n","    return groups"],"metadata":{"id":"5oApNm90RNF4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["uses=[]\n","for k,v in nans_groups.items():\n","    if len(v)>1:\n","            Vs = nans_groups[k]\n","            grps= group_columns_by_correlation(df_train[Vs], threshold=0.8)\n","            use=reduce_group(grps)\n","            uses=uses+use\n","    else:\n","        uses=uses+v\n","\n","# Subset the DataFrame to keep only the selected columns\n","df_train = df_train[uses]\n","df_train.columns"],"metadata":{"id":"K6szxE--ZDsG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Preparation for Test Set"],"metadata":{"id":"tmoOpOUqZSCd"}},{"cell_type":"code","source":["# ROOT_hack = Path(\"/kaggle/input/home-credit-credit-risk-modeling\")\n","\n","# TEST_DIR = ROOT_hack / \"parquet_files\" / \"test\"\n","# TEST_DIR = \"/content/parquet_files/test\"\n","TEST_DIR = \"/content/test_dataset/transformed\"    # put test.parquet in this folder"],"metadata":{"id":"96fnFoujYz8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_store = {\n","    \"df_base\": read_file(TEST_DIR + \"/test.parquet\"),\n","    \"depth_0\": [\n","        read_file(TEST_DIR + \"/test_static_cb_0.parquet\"),\n","        read_file(TEST_DIR + \"/test_static_0_0.parquet\"),\n","    ],\n","    \"depth_1\": [\n","        read_file(TEST_DIR + \"/test_applprev_1_0.parquet\", 1),\n","        read_file(TEST_DIR + \"/test_credit_bureau_a_1_0.parquet\", 1),\n","        read_file(TEST_DIR + \"/test_credit_bureau_b_1.parquet\", 1),\n","        read_file(TEST_DIR + \"/test_debitcard_1.parquet\", 1),\n","        read_file(TEST_DIR + \"/test_deposit_1.parquet\", 1),\n","        read_file(TEST_DIR + \"/test_other_1.parquet\", 1),\n","        read_file(TEST_DIR + \"/test_person_1.parquet\", 1),\n","        read_file(TEST_DIR + \"/test_tax_registry_a_1.parquet\", 1),\n","        read_file(TEST_DIR + \"/test_tax_registry_b_1.parquet\", 1),\n","    ],\n","    \"depth_2\": [\n","        read_file(TEST_DIR + \"/test_applprev_2.parquet\", 2),\n","        read_file(TEST_DIR + \"/test_credit_bureau_a_2_0.parquet\", 2),\n","        read_file(TEST_DIR + \"/test_credit_bureau_b_2.parquet\", 2),\n","        read_file(TEST_DIR + \"/test_person_2.parquet\", 2),\n","    ]\n","}"],"metadata":{"id":"RB3eRcmaYz4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test = feature_eng(**data_store)\n","print(len(df_test.columns))\n","del data_store\n","gc.collect()\n","df_test = df_test.pipe(Pipeline.filter_cols)\n","print(len(df_test.columns))\n","df_test, _ = to_pandas(df_test, cat_cols)\n","print(len(df_test.columns))\n","df_test = reduce_mem_usage(df_test)\n","df_test"],"metadata":{"id":"PB4lpW4ci9ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for col in df_test.columns:\n","#     if df_test[col].dtype == 'object':\n","#         df_test[col] = df_test[col].astype('str').fillna('-1')\n","\n","encoder = OrdinalEncoder()\n","encoder.fit(df_test[cat_cols])"],"metadata":{"id":"Gbs97oCb5a5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df_train.columns), len(df_test.columns)"],"metadata":{"id":"yG4cZMtE66yw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.get('target').value_counts()"],"metadata":{"id":"xQtaKTRGt70U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Combining and Preparing Data for Modeling"],"metadata":{"id":"7LwCJoQ4nZoe"}},{"cell_type":"code","source":["y = df_train_balanced[\"target\"]\n","df_train_balanced = df_train_balanced.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"])\n","df_train_balanced = reduce_mem_usage(df_train_balanced)\n","joblib.dump((df_train_balanced, y, df_test), 'data.pkl')"],"metadata":{"id":"keqOMJgPnaC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df_train_balanced.columns)"],"metadata":{"id":"6ypsFmUowS-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len((set(df_train_balanced.columns)).intersection(set(df_test.columns)))"],"metadata":{"id":"8aCXB8o8wcwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train, y, df_test = joblib.load('/content/data.pkl')\n","df_train.shape, df_test.shape"],"metadata":{"id":"WI1z4PcXw-Dt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["indexx = df_test['case_id']\n","indexx"],"metadata":{"id":"BbBiIVaD3lXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"id":"yDBJ3eci8is_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["miss_cols_test = list(set(df_test.columns) - set(df_train.columns))\n","miss_cols_test"],"metadata":{"id":"6mSt7z5_yZjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test = df_test.drop(columns=miss_cols_test)\n","len(df_test.columns)"],"metadata":{"id":"skXfoEpKzmqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if set(df_test.columns) == set(df_train.columns):\n","  print(True)"],"metadata":{"id":"-EohVbl30IlT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Assuming df_train and df_test are your DataFrames\n","\n","# Get data types of each column in both DataFrames\n","train_dtypes = df_train.dtypes\n","test_dtypes = df_test.dtypes\n","\n","# Find columns with different data types\n","different_dtypes = {col: (train_dtypes[col], test_dtypes[col]) for col in df_train.columns if train_dtypes[col] != test_dtypes[col]}\n","\n","# Print the columns with different data types\n","# for col, (train_dtype, test_dtype) in different_dtypes.items():\n","#     print(f\"Column '{col}' has different data types: Train -> {train_dtype}, Test -> {test_dtype}\")"],"metadata":{"id":"PCtaa8E2M3S3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list(different_dtypes.keys()), len(different_dtypes)"],"metadata":{"id":"GGBrVQJ0NMeo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_sametype = df_train.drop(columns=list(different_dtypes.keys()))\n","test_sametype = df_test.drop(columns=list(different_dtypes.keys()))\n","len(train_sametype.columns), len(test_sametype.columns)"],"metadata":{"id":"F3-9cTQjNoFo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2xDOCGTGNHuv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train Model"],"metadata":{"id":"lExDpEbKLTbS"}},{"cell_type":"code","source":["fitted_models_lgb = []\n","\n","params = {\n","    \"boosting_type\": \"gbdt\",\n","    \"objective\": \"binary\",\n","    \"metric\": \"auc\",\n","    \"max_depth\": 3,\n","    \"num_leaves\": 31,\n","    \"learning_rate\": 0.05,\n","    \"feature_fraction\": 0.9,\n","    \"bagging_fraction\": 0.8,\n","    \"bagging_freq\": 5,\n","    \"n_estimators\": 1000,\n","    \"verbose\": -1,\n","}\n","mo_1 = lgb.LGBMClassifier(**params)\n","mo_1.fit(train_sametype, y)\n","fitted_models_lgb.append(mo_1)"],"metadata":{"id":"LueawGzP8q9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from catboost import CatBoostClassifier\n","\n","params = {\n","    \"iterations\": 1000,                  # Equivalent to n_estimators\n","    \"depth\": 3,                          # Equivalent to max_depth\n","    \"learning_rate\": 0.05,\n","    \"l2_leaf_reg\": 3.0,                  # Equivalent to lambda_l2 in LightGBM\n","    \"bootstrap_type\": \"Bernoulli\",       # Equivalent to bagging\n","    \"subsample\": 0.8,                    # Equivalent to bagging_fraction\n","    \"rsm\": 0.9,                          # Equivalent to feature_fraction\n","    \"verbose\": 0,\n","    \"eval_metric\": \"AUC\",                # Equivalent to metric\n","    \"random_seed\": 42,                   # To ensure reproducibility\n","}\n","\n","mo_2 = CatBoostClassifier(**params)\n","mo_2.fit(train_sametype, y)\n","fitted_models_lgb.append(mo_2)"],"metadata":{"id":"93J7PV8X-Ct5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VotingModel(BaseEstimator, RegressorMixin):\n","    def __init__(self, estimators):\n","        super().__init__()\n","        self.estimators = estimators\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def predict(self, X):\n","        y_preds = [estimator.predict(X) for estimator in self.estimators]\n","        return np.mean(y_preds, axis=0)\n","\n","    def predict_proba(self, X):\n","        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n","        return np.mean(y_preds, axis=0)\n","\n","model = VotingModel(fitted_models_lgb)\n","model"],"metadata":{"id":"X3h7GZYo81AI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Prediction"],"metadata":{"id":"S6xB5uOYjmKG"}},{"cell_type":"code","source":["np.mean(model.predict_proba(test_sametype), axis=1)"],"metadata":{"id":"zMXARb6WSQ2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict_proba(test_sametype)[:,1]"],"metadata":{"id":"9sDItYDlTti3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = pd.Series(model.predict_proba(test_sametype)[:,0], index=test_sametype.index)\n","y_pred"],"metadata":{"id":"-NsynHh_806n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub = pd.DataFrame({\n","    \"case_id\": indexx, \"target\": y_pred\n","})\n","sub"],"metadata":{"id":"hn2ojunBtORU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_subm = pd.read_csv(\"/content/sample_submission.csv\")\n","df_subm"],"metadata":{"id":"ZnHwDzae8kYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_subm = df_subm.drop(columns=['target'])\n","merged_df = df_subm.merge(sub, on=\"case_id\", how=\"left\")\n","merged_df"],"metadata":{"id":"OSUvTioGPaRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df.to_csv(\"lgb_cb_0.csv\", index=False)"],"metadata":{"id":"R6Ty5WccPhfu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged_df[merged_df['target'] == 1]"],"metadata":{"id":"89ZKDWCvPdrt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"80dtZfaaPEYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"94H9q__szI4I"},"execution_count":null,"outputs":[]}]}